{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import libraries and define functions (to hang out in global scope)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_weights(model):\n",
    "    for layer in model.layers:\n",
    "        W = layer.get_weights()[0]\n",
    "\n",
    "        for i in range(W.shape[2]):\n",
    "            for j in range(W.shape[3]):\n",
    "                print(W[:,:,i,j])\n",
    "                plt.subplot(W.shape[2], W.shape[3], 1+j+i*W.shape[3])\n",
    "                plt.imshow((W[:,:,i,j]+1)/2, cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def show_board(board):\n",
    "    for row in board:\n",
    "        for piece in row:\n",
    "            if piece[2]:\n",
    "                letter = 'K'\n",
    "            elif piece[3]:\n",
    "                letter = 'Q'\n",
    "            elif piece[4]:\n",
    "                letter = 'R'\n",
    "            elif piece[5]:\n",
    "                letter = 'N'\n",
    "            elif piece[6]:\n",
    "                letter = 'B'\n",
    "            elif piece[7]:\n",
    "                letter = 'P'\n",
    "            else:\n",
    "                letter = '.'\n",
    "\n",
    "            if piece[1]:\n",
    "                letter = letter.lower()\n",
    "\n",
    "            print(letter, end='')\n",
    "        print()\n",
    "\n",
    "def show_moves(moves):\n",
    "    for row in moves:\n",
    "        for move in row:\n",
    "            move = 'X' if move[0] else '.'\n",
    "            print(move, end='')\n",
    "        print()\n",
    "\n",
    "print(\"Done importing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define handcrafted filters and data representation specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FILTERS = {\n",
    "    'neutral': np.zeros((3,3,1)),\n",
    "}\n",
    "for j in range(3):\n",
    "    for i in range(3):\n",
    "        filter = np.zeros((3,3,1))\n",
    "        filter[i][j] = 1\n",
    "        FILTERS['pos'+str(i+j*3)] = filter\n",
    "        \n",
    "        \n",
    "# def make_weight(filters):\n",
    "    \n",
    "\n",
    "# WEIGHTS = {\n",
    "#     'whitebishop': make_weight({'white':'pos4','bishop':'pos4'})\n",
    "    \n",
    "#     [np.array(\n",
    "#             #   Wh   Bl    K    Q    R    N    B    P   mv   ep\n",
    "#             [[[[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]]],\n",
    "#              [[[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 2],[ 0],[ 0],[ 0],[ 0],[ 0],[ 2],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]]],\n",
    "#              [[[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]]]]\n",
    "#         ),\n",
    "#         np.array([-3])],\n",
    "#     'pos0_whitebishop': [np.array(\n",
    "#             #   Wh   Bl    K    Q    R    N    B    P   mv   ep   wb\n",
    "#             [[[[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 1]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]]],\n",
    "#              [[[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]]],\n",
    "#              [[[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]],\n",
    "#               [[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0],[ 0]]]]\n",
    "#         ),\n",
    "#         np.array([0])],\n",
    "# }\n",
    "\n",
    "# WEIGHTS['whitebishop'] = \n",
    "\n",
    "TRAINING_SIZE = 19000\n",
    "TOTAL_SIZE = 31000\n",
    "\n",
    "piece_to_id = {\n",
    "\t'K':[1,0,0,0,0,0],\n",
    "\t'Q':[0,1,0,0,0,0],\n",
    "\t'R':[0,0,1,0,0,0],\n",
    "\t'N':[0,0,0,1,0,0],\n",
    "\t'B':[0,0,0,0,1,0],\n",
    "\t'P':[0,0,0,0,0,1],\n",
    "}\n",
    "\n",
    "LAYERS = [\n",
    "    'white',\n",
    "    'black',\n",
    "    'king',\n",
    "    'queen',\n",
    "    'rook',\n",
    "    'knight',\n",
    "    'bishop',\n",
    "    'pawn',\n",
    "    'has_moved',\n",
    "    'enpassant',\n",
    "]\n",
    "\n",
    "cache = defaultdict(str)\n",
    "\n",
    "print(\"Ok.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "i = 0\n",
    "for line in csv.reader(open('moves.csv'), delimiter='|'):\n",
    "    i+= 1\n",
    "    if i > TOTAL_SIZE:\n",
    "        break\n",
    "\n",
    "    player = 1 if int(line[0]) == 1 else 0\n",
    "    if not player:\n",
    "        continue\n",
    "\n",
    "    found_bishop=False\n",
    "\n",
    "    colors = [[1,0]]*16 + [[0,1]]*16\n",
    "    pieces = [piece_to_id[char] for char in line[2].split(',')]\n",
    "    has_moved = [([1] if n!='0' else [0]) for n in line[3].split(',')]\n",
    "    enpassant = [[0]]*32\n",
    "    if line[4]:\n",
    "        enpassant[int(line[4])-1] = [1]\n",
    "\n",
    "    squares = []\n",
    "    for row in chunks(line[1].split(','), 8):\n",
    "        rank = []\n",
    "        for id in row:\n",
    "            if not id:\n",
    "                square = [0,0] + [0]*6 + [0] + [0]\n",
    "            else:\n",
    "                id = int(id)-1\n",
    "                if pieces[id] == [0,0,0,0,1,0]:\n",
    "                    found_bishop = True\n",
    "                square = colors[id] + pieces[id] + has_moved[id] + enpassant[id]\n",
    "            rank.append(square)\n",
    "        squares.append(rank)\n",
    "\n",
    "    if not found_bishop:\n",
    "        continue\n",
    "\n",
    "    X.append(squares)\n",
    "\n",
    "    destinations = []\n",
    "    for line in chunks(line[5].split(','), 8):\n",
    "        destinations.append([(1 if n!='0' else 0) for n in line])\n",
    "    Y.append(destinations)\n",
    "\n",
    "X = np.array(X).astype('float32')\n",
    "Y = np.array(Y)\n",
    "Y = np.expand_dims(Y, 3)\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heart of the matter! Find new features to add to the board representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3, 3), padding='same', activation='relu', input_shape=(8,8,1)))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.mean_squared_error,\n",
    "    metrics=['accuracy', keras.metrics.TruePositives()]\n",
    ")\n",
    "\n",
    "best_accuracy = 0\n",
    "best_TPR = 0\n",
    "best_filter = ''\n",
    "best_property = None\n",
    "while 'neutral_white' not in LAYERS:\n",
    "    for key, filter in FILTERS.items():\n",
    "        model.layers[0].set_weights([\n",
    "                np.expand_dims(np.array(filter), 3),\n",
    "                np.array([0])\n",
    "        ])\n",
    "        # plot_weights(model)\n",
    "\n",
    "        for i, X_slice in enumerate(np.split(X, X.shape[3], 3)):\n",
    "            if key+'_'+LAYERS[i] in LAYERS:\n",
    "                print(\"Already considering\", key+'_'+LAYERS[i])\n",
    "                continue\n",
    "            if key+'_'+LAYERS[i] not in cache:\n",
    "                cache[key+'_'+LAYERS[i]] = model.evaluate(X_slice, Y, verbose=0)\n",
    "                print(key, LAYERS[i], 'accuracy:', cache[key+'_'+LAYERS[i]][1])\n",
    "            score = cache[key+'_'+LAYERS[i]]\n",
    "#             print(key, LAYERS[i], 'TPR:', score[2])\n",
    "            if best_accuracy + 0.00000001 < score[1]:\n",
    "                best_accuracy = score[1]\n",
    "                best_property = i\n",
    "                best_filter = key\n",
    "            if key=='neutral':\n",
    "                break\n",
    "\n",
    "    if best_filter+'_'+LAYERS[best_property] in LAYERS:\n",
    "        print(\"Could not improve result with basic filters.\")\n",
    "        break\n",
    "                \n",
    "    print(best_filter, 'got an accuracy of', best_accuracy, 'on', LAYERS[best_property])\n",
    "\n",
    "    model.layers[0].set_weights([\n",
    "        np.expand_dims(np.array(FILTERS[best_filter]), 3),\n",
    "        np.array([0])\n",
    "    ])\n",
    "\n",
    "    Y_prob = (model.predict(np.split(X, X.shape[3], 3)[best_property]) > .5).astype('int')\n",
    "\n",
    "    for i, y_prob in enumerate(Y_prob):\n",
    "        if not (y_prob == Y[i]).all():\n",
    "            show_board(X[i])\n",
    "            print()\n",
    "            show_moves(y_prob)\n",
    "            print()\n",
    "            show_moves(Y[i])\n",
    "            print('-----')\n",
    "            break\n",
    "            \n",
    "    X = np.concatenate((X, Y_prob), 3)\n",
    "    LAYERS.append(best_filter+'_'+LAYERS[best_property])\n",
    "    print(\"Appended\", best_filter+'_'+LAYERS[best_property], 'to LAYERS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the generated board representation to train a simple network that finds the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X[:TRAINING_SIZE]\n",
    "Y_train = Y[:TRAINING_SIZE]\n",
    "X_test  = X[TRAINING_SIZE:]\n",
    "Y_test  = Y[TRAINING_SIZE:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(5, (3, 3), padding='same', activation='relu', input_shape=X[0].shape))\n",
    "model.add(Conv2D(1, (3, 3), padding='same', activation='relu'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.mean_squared_error,\n",
    "#     optimizer=keras.optimizers.Adam(\n",
    "#         learning_rate=0.1,\n",
    "#         beta_1=0.9,\n",
    "#         beta_2=0.999,\n",
    "#         amsgrad=False,\n",
    "#     ),\n",
    "    optimizer=keras.optimizers.SGD(lr=0.1, nesterov=True),\n",
    "#     optimizer=keras.optimizers.Adadelta(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model = load_model('best_model.h5')\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    shuffle=True,\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            filepath='best_model.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1,\n",
    "        )]\n",
    ")\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display positions that the model fails on, with the predicted and correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_prob = (model.predict(X_test) > .5).astype('int')\n",
    "\n",
    "for i, y_prob in enumerate(Y_prob):\n",
    "\n",
    "    if not (y_prob == Y_test[i]).all():\n",
    "        show_board(X_test[i])\n",
    "        print()\n",
    "        show_moves(y_prob)\n",
    "        print()\n",
    "        show_moves(Y_test[i])\n",
    "        print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_weights(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
